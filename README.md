# 🤖 AI-Resume-Matcher

A **Pro-Level AI Resume Screening System** that matches resumes with job descriptions using **SBERT-based semantic similarity** and explains matches using **LLaMA 3 (Mistral) via Ollama** — all fully offline. Perfect for **privacy-first organizations** seeking accurate and explainable resume screening without cloud dependencies.

## 🚀 Features

- ✅ **Semantic Resume-Job Matching** via SBERT (`all-MiniLM-L6-v2`)
- ⚡ **Top-k Match Retrieval** using cosine similarity
- 🧾 **PDF Resume Parsing** using `pdfplumber`
- 💡 **Human-like Reasoning** generated by **Mistral model via Ollama**
- 🔐 **Fully Offline** — no APIs or internet required
- 📊 **Match Confidence Scores**
- 📁 **Export Results** as CSV/JSON with LLM-generated explanations
- 🖥️ **Streamlit UI** with file upload, progress bar, pagination

## 🖼️ Screenshots & Architecture

### 🔹 System Architecture Flow
![Architecture](images/architecture.png)

### 🔹 Alternative Flow Diagram
![Alternative Architecture](images/architecture-alt.png)

### 🔹 Streamlit UI Preview
![UI Screenshot](images/ui-screenshot.png)

## 🧱 Tech Stack

- **Language**: Python
- **Models**:
  - Sentence-BERT: `all-MiniLM-L6-v2`
  - Local LLM via Ollama: `mistral`
- **Libraries**: `streamlit`, `pdfplumber`, `sentence-transformers`, `pandas`, `numpy`, `subprocess`
- **Local Model Tool**: [Ollama](https://ollama.com/)

## 🔧 Installation

### 1. Clone the repository

```bash
git clone https://github.com/drshn-git/AI-Resume-Matcher.git
cd AI-Resume-Matcher
```

### 2. Create a virtual environment

```bash
python -m venv venv
source venv/bin/activate       # On Windows: venv\Scripts\activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

## 🧠 Setup Local LLM (Mistral via Ollama)

### 1. Install Ollama:  
👉 [https://ollama.com](https://ollama.com)

### 2. Pull the Mistral Model:

```bash
ollama pull mistral
```

## ▶️ Run the App

```bash
streamlit run app.py
```

Then open your browser to [http://localhost:8501](http://localhost:8501)

## 📦 Output

Results will be stored in the `output/` folder with resume match info, scores, and LLM explanations.

## 🛡️ License

MIT License (added)
